# COMPARATIVE STUDY OF Hybrid RECOMMENDATION SYSTEMS

The rapidly developing e-commerce sector has increased the demand for effective recommendation systems to provide clients with personalized and accurate product recommendations. These systems are critical in improving the customer experience, increasing sales, and cultivating customer loyalty. While traditional recommendation systems depend solely on star ratings for evaluating customer satisfaction, recent research has demonstrated the value of using sentiment analysis to capture the nuances and emotions represented in textual evaluations. This dataset, sourced from the Amazon website, comprises user reviews, star ratings, and anonymized product information. It is the foundational resource for our comparative analysis of various hybrid recommendation systems.

This project aims to contribute to the area by comparing hybrid recommendation systems for e-commerce, emphasising integrating sentiment analysis and star ratings using the weighted hybrid approach. Other objectives of this project include:

- Performing sentiment analysis on customer reviews.
- Analyze the direction and strength of the correlation to assess the alignment between
sentiment and star ratings
- Identifying keywords used in customer reviews and exploring the relationship between keywords and customer behaviours.

### Data Preparation

Given the computational needs of deep learning models, especially the BERT model used in this project, the initial steps were performed on Google Colab, a cloud-based platform that offers GPU runtime capabilities. Utilizing the Python pandas library, the data was imported from a CSV file stored on Google Drive. The dataset presents an array of attributes, with the key columns being 'overall' (representing star ratings), 'reviewerID', 'asin' (product ID), and 'reviewText' (the textual content of the review). A snapshot inspection of the dataset was carried out to gain an initial understanding of its structure and the nature of the stored data.


Text preprocessing plays a crucial role in enhancing the quality and consistency of data. To achieve this, several measures were implemented in the review texts. Firstly, the review texts were converted to lowercase, ensuring uniformity and eliminating potential discrepancies arising from variant text cases. Subsequently, any non-alphabetic characters were purged from the text, which allows for more precise tokenization and sentiment analysis. The tokenization process then came into play, where the text was systematically divided into individual words or tokens, a fundamental procedure in the Natural Language Processing (NLP) continuum as it segments the text into analyzable fragments. Once tokenized, lemmatization was executed on each word, converting them to their base or root forms. This action ensures that diverse word forms with an identical root meaning, exemplified by words like 'running', 'runs', and 'ran', are uniformly recognized as 'run'. During this step, a specialized function, get_wordnet_pos, was employed to map the part-of-speech tags from NLTK's pos_tag function to those identified by WordNet, thereby refining the lemmatization process. As a result of these combined measures, the review text column in the data frame underwent comprehensive preprocessing, priming it for subsequent feature extraction. Lastly, the Term Frequency-Inverse Document Frequency (TF-IDF) technique was utilized to metamorphose the preprocessed text into a matrix of features. This method assigns values to words based on their significance in a document about their prevalence in the broader corpus. To optimize this, words with common occurrences across documents, often labelled "stop words" due to their lack of distinctive insights, were intentionally left out.

### Exploratory  Analysis 

During the exploratory analysis phase, descriptive statistics were leveraged to succinctly represent the central tendency, dispersion, and shape of the 'star ratings' and subsequently introduced 'sentiment scores' distributions. Histograms visually represented these distributions, making identifying patterns or anomalies straightforward. Additionally, to ensure the integrity and accuracy of the analysis, outlier detection was meticulously executed on the 'star ratings' and 'sentiment' columns. Using specific criteria, rows that fell outside the expected range (1 to 5) for both 'star ratings' and 'sentiment' were isolated. However, after a thorough examination, it was determined that neither the 'star ratings' nor 'sentiment' columns had any outliers, ensuring the robustness of the dataset. Building on these insights, a correlation heatmap was crafted using Pearson correlation coefficients. This heatmap was a powerful tool to visually depict and numerically quantify the degree of linear relationship between the star ratings and the calculated sentiment scores. Finally, a chi-square statistical test was performed to determine the correlation strength by first discretizing the sentiment and star ratings into categories.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/Histogram%20dist%20star%20and%20sentiment.png)

### Sentiment Analysis Approach

The sentiment analysis was primarily driven by a pre-trained BERT (Bidirectional Encoder Representations from Transformers) model due to its advantages, including its benchmark-setting performance, its ability to grasp contextual word subtleties because of its bidirectional nature, and its transfer learning advantages from pre-training on large text corpora. Specifically, a fine-tuned variant of the BERT model intended for sentiment classification on the IMDB dataset was employed. Sourced from the Transformers library, this model stands at the forefront of natural language processing and is renowned for its prowess in sentiment extraction from textual reviews. For the sentiment analysis, each review undergoes a series of transformations. Firstly, the review text is tokenized and formatted to be compatible with the BERT model. This involves segmenting the text into chunks or tokens and encoding them into a format the BERT model can understand. Given the vastness of certain reviews, they might exceed BERT's maximum input length, thus necessitating truncation to fit within the limit. To maximize efficiency and reduce computational time, the model's operations were executed on the GPU runtime provided by Google Colab, a platform that allows for robust cloud-based computations. Once the input is prepared, it's transferred to the GPU for fast processing. Utilizing the GPU over a traditional CPU ensures that the vast matrix operations inherent in deep learning models like BERT are executed swiftly, leading to quicker sentiment score derivations for each review. The model then processes these tokenized reviews and provides an output consisting of logits or raw prediction scores for each sentiment category. These logits are then passed through a softmax function to transform them into probabilities. The sentiment score for each review is computed by taking the difference between the probabilities of the positive and negative classes. This sentiment score captures the polarity of the sentiment, with positive values indicating a positive sentiment and negative values indicating a negative sentiment.

Given that the original star ratings lie within a range of 1 to 5, aligning the sentiment scores with this scale is crucial. To achieve this alignment, the MinMaxScaler from the sklearn library was employed. This scaler transformed the sentiment scores to fit within the range of 1 to 5, mirroring the original star ratings range. However, the nature of star ratings is inherently discrete, meaning they often exist as whole numbers. The scaled sentiment scores were rounded to the nearest whole number to emulate this and facilitate straightforward comparisons. By the end of this process, each review in the dataset had a corresponding sentiment score, offering a machine-driven perspective on its sentiment tailored to mirror the original star ratings.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/Screenshot%202024-02-11%20at%2016.06.34.png)

### Customer behaviour Analysis
To better understand customer behaviour, reviews were delved into to extract key insights. Using the TF-IDF method, which measures a word's importance in a document relative to a collection of documents, the reviews were converted into an organized data frame, allowing for easier analysis. Reviews were then categorized by their star ratings: those rated 4 or higher were considered positive, highlighting what customers liked, while those rated 2 or lower pointed out areas for improvement.

This classification made it possible to gather TF-IDF scores specific to each sentiment. The core of this analysis identified the top 10 recurring words in both positive and negative reviews. Bar charts vividly displayed the main topics in both positive and negative feedback. Additionally, word clouds were used for each sentiment category. These clouds visually emphasized the most important words: the more significant the word, the larger its display. Words frequently linked with customer satisfaction stood out in the positive cloud, while the negative cloud highlighted common customer concerns. These visuals offer a quick yet deep dive into customer opinions, aiding in informed future decisions.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/positive%20comments.png)

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/negative%20comments.png)

The word frequency analysis illuminated the specific terminologies recurrent in customer reviews. For those expressing satisfaction, keywords like 'Great', 'use', 'work', 'good', 'easy', 'product', 'year', 'love', 'program' and ‘software’ were top 10, reflecting contentment, practicality, and a generally affirmative experience with the product or service. In contrast, reviews tinged with dissatisfaction frequently featured terms such as 'work', 'product', 'software', 'use', 'program', 'buy', 'version', 'computer', 'try' and ‘time’. From these, it's evident that many negative sentiments stemmed from functionality-related issues, challenges with specific software versions, and overarching concerns about usability.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/top%2010.png)

### Star Ratings Correlation with Sentiment Analysis

The correlation between sentiment scores and star ratings was notably high, with a Pearson's correlation coefficient of 0.7501. This suggests a strong positive relationship between the review's sentiment and the given star rating. In simpler terms, reviews with positive sentiments tend to have higher star ratings and vice versa. Further statistical verification was conducted using the Chi-squared test, resulting in a value of 254,699.58. The associated P-value was 0.0, indicating this correlation is statistically significant.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/corr.png)

### Model Development

A subset of 70,000 samples was chosen from the main dataset. This decision was made to manage computational limitations, ensuring the model development went smoothly without system hiccups. The data was partitioned into an 80-20 split, with 80% allocated for training to allow the model to adequately learn and recognize patterns and 20% reserved for testing to verify the model's predictive accuracy and prevent overfitting, thereby ensuring a well-rounded evaluation of its performance (Najafabadi et al., 2015). To make sure these steps would not be repeated in the future, the processed data and the training-test sets were saved as CSV files and uploaded to one drive.

Various aspects were considered in selecting acceptable models for this project to ensure the highest degree of accuracy and relevance to the specific nature of the task. The Random Forest model was chosen for its remarkable accuracy and classification abilities, particularly in interpreting complex sentiment categories. This model is well-known for handling high-dimensional spaces and large numbers of training examples, making it especially adept at deciphering the subtle sentiment data in our dataset (Al Amrani et al., 2018). Similarly, Logistic

Regression was selected as a key component of the hybrid approach owing to its proven efficiency and balanced classification outcomes in star rating predictions. This model, characterized by its simplicity and the ability to provide probabilities and classifications, allows for a more nuanced understanding and prediction of user ratings. Its unparalleled accuracy in predicting star ratings is a critical tool for comprehensively analysing user sentiments, aligning with the project's goal to delve deep into user reviews to provide precise recommendations (Shakhovska et al., 2020). Furthermore, incorporating the Recurrent Neural Network (RNN) was prompted by its ability to analyse sequential input. Given the textual nature of the sentiment analysis component of this research, RNNs' ability to analyse patterns and sequences in text data is critical. This is primarily because RNNs can use their internal state (memory) to process sequences of inputs, allowing them to discover intricate patterns within data that would be beyond the capability of conventional models. This characteristic makes RNNs particularly well-suited for tasks involving sentiment analysis and star rating prediction, aiming to significantly enhance the efficacy of the recommendation system through a better understanding of user sentiments. (An et al., 2018).

By integrating these models into a unified framework, the project seeks to leverage the distinct strengths of each, fostering a synergistic effect that would facilitate more nuanced and accurate recommendations than could be achieved using any single model in isolation. Moreover, these models were chosen for their complementary strengths, offering a balanced and robust approach to tackling the multi-faceted challenges in the e-commerce domain.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/pipeline.png)

- Random Forest for Sentiment-Based Model: A Random Forest classifier was employed for the sentiment model. The ratings were binarized using a threshold of 4, marking ratings of 4 and above as positive (encoded as 1) and the rest as negative (encoded as 0). The reviews underwent vectorization through the TF-IDF vectorizer, focusing on the top 5,000 terms by frequency. To ensure unbiased learning, especially in scenarios with significant class imbalances, the Random Forest was set with balanced class weights. Post-training, the model furnished class probabilities and straightforward class predictions for the test dataset.
- Recurrent Neural Network for Sentiment-Based model: In the development of sentiment models using RNN, TensorFlow played a pivotal role. Reviews were tokenized, focusing on the most frequent 5,000 words from the training data, and sequences were standardized to a consistent length of 200. Using the earlier stipulated threshold, star ratings underwent a transformation into a binary format. The RNN's structural blueprint encompassed an embedding layer set to a 200-length input and 64 dimensions. This was followed by a 64-unit RNN layer with L2 regularization and sequence returns. A dropout layer with a 0.5 rate was integrated to mitigate the risk of overfitting. Subsequent layers included a second RNN layer with 32 units and L2 regularization, culminating in a dense output layer utilizing a sigmoid activation function tailored for binary classification. The training was fine-tuned using the Adam optimizer, configured with a 0.001 learning rate, and to further fortify against overfitting, early stopping was implemented with a patience threshold of three.
- Logistic Regression for Star Rating Based Model: A Logistic Regression approach was adopted for the star rating model. Initially, star ratings were transformed into a binary format using a threshold of 4. This was followed by applying TF- IDF vectorization to the review texts, emphasizing the top 5,000 words. The logistic regression model was trained with this preprocessed data, setting the maximum iterations at 1000 to ensure optimal convergence. The model's performance was gauged upon completion, and subsequent predictions were executed on the test set.
- Recurrent Neural Network for Star Rating Based Model: An RNN model was brought into play for the star rating prediction, taking cues from the RNN framework previously employed for sentiment analysis. Star ratings underwent a binary conversion. Subsequently, the reviews were tokenized, spotlighting the top 5,000 words, and then tailored to a consistent length of 50 through padding. Structurally, the RNN was designed with an embedding layer featuring 50 dimensions. This segued into a simple RNN layer, equipped with 512 units and endowed with L2 regularization on the kernel, recurrent connections, and bias. A dropout layer, set at a rate of 0.5, was introduced to counter overfitting. The architecture was completed with a dense output layer, employing a sigmoid activation function for binary classification. Training of the model hinged on the RMSProp optimizer, with the added measure of early stopping to preempt overfitting.

### Hybrid models

Some hybrid models combined many distinct models were created in the search for a better prediction model. The key to creating hybrid models is using one model's advantages to partially compensate for another's weaknesses, aiming for a balanced and effective prediction process. This fusion intended to improve performance on unexplored data by leveraging the distinct predicting abilities of each algorithm rather than merely combining them. A weighted sum of the probability scores from the two models served as the foundation of the hybrid strategy. The weighted score of a particular data point can be expressed as;

𝑊𝑒𝑖𝑔h𝑡𝑒𝑑 𝑠𝑐𝑜𝑟𝑒 = 𝑤 × 𝑃𝑟𝑜𝑏𝑎𝑏𝑖𝑙𝑖𝑡𝑦 𝑀𝑜𝑑𝑒𝑙 𝐴 + (1 − 𝑤) × 𝑃𝑟𝑜𝑏𝑎𝑏𝑖𝑙𝑖𝑡𝑦 𝑀𝑜𝑑𝑒𝑙 𝐵

where 'w' signifies the weight factor, oscillating between 0 and 1. We embarked on an exhaustive search across varied weight magnitudes to pin down the quintessential weight for the best synergy.

- Hybrid of Random Forest (Sentiment) & Logistic Regression (Ratings): In Model 1, the sentiment predictions from a Random Forest model are merged with rating predictions from a Logistic Regression model. A tree-based model like Random Forest might capture nonlinear interactions in the sentiment data, whereas the Logistic Regression model will likely capture linear relationships in the ratings data. The hybrid scores are obtained by taking a weighted average of the predicted probabilities from both models. We can find the optimal balance between the two models' predictions by iterating over different weights to maximize the ROC-AUC.
- Hybrid of RNN (Sentiment model) & RNN (Rating model): Model 2 combines the power of two RNNs - one trained on sentiment and another on ratings. RNNs, being sequential models, are particularly suited for tasks where order matters, like time series data or text. In this setup, the sentiment and ratings might have sequence-based patterns that the RNNs can capture. By adjusting the weightings of these two RNN outputs, the hybrid model tries to find the best combination of sentiment-based sequential patterns with rating-based sequential patterns.
- Hybrid of Sentiment model (Random Forest) and Rating model (RNN): Model 3 is an interesting mix of a tree-based model (Random Forest) for sentiment and a sequential model (RNN) for ratings. The idea here is to combine the non-linear pattern-capturing ability of Random Forests with the sequential pattern-capturing ability of RNNs. This can be particularly powerful if, for instance, sentiment has complex interactions between features and ratings have sequential dependencies.
- Hybrid of Sentiment model (RNN) and Ratings model (Logistic Regression): In Model 4, the RNN captures sequential patterns in sentiment data, while the Logistic Regression captures linear patterns in the ratings data. This hybrid model believes in the strength of RNNs in capturing sequences in sentiments and the straightforward relationships in ratings, which a logistic regression can tackle efficiently. For each of these models, different weights are tried for the outputs of the two underlying models to find the combination that gives the highest ROC- AUC. This optimization helps find the best balance between the combined two models.

### Evaluation and Findings
In this research, a rigorous evaluation process using standard metrics to gauge the efficacy of each model was employed. Setting a rating threshold of 4, with reviews scoring 4 or above classified as 'Recommended'. This distinction clarified the underlying sentiment of each review. Precision gauged the proportion of accurately labelled 'Recommended' reviews, showcasing our model's reliability. Meanwhile, Recall reflected the model's skill in capturing genuine 'Recommended' reviews. The F1 Score, harmonizing Precision and Recall, became especially vital in uneven datasets, with a score near 1 indicating model excellence. Accuracy offered a snapshot of the model's overall capability in identifying correct reviews, while the ROC Curve and AUC provided a visual and holistic assessment of the model's performance, respectively. With an AUC close to 1 denoting superior predictive prowess. By leveraging these metrics, the research elucidates each model's performance nuances, enhancing the credibility of our primary conclusions.

#### Performance Metrics of Traditional Models
The Random Forest sentiment model showcases a strong performance with an accuracy of 0.82, recall of 0.86, and precision of 0.85, further affirmed by its 0.85 F1 score and 0.90 ROC score. The RNN sentiment model, while slightly less accurate at 0.81, maintains a good balance of precision (0.86) and recall (0.83), resulting in an F1 score of 0.85 and an ROC score of 0.89, indicating a slight preference towards precision and a robust discriminatory power. In the star rating comparison, the Logistic Regression model stands out with the highest accuracy of 0.86, a uniform score of 0.85 across recall, precision, and F1 score, and a notable ROC score of 0.93, demonstrating excellent classification and balance. On the other hand, the RNN star rating model, though slightly lagging with an accuracy of 0.83 and scores around 0.82-0.83 for recall, precision, and F1, still presents a solid performance with a ROC score of 0.91, hinting at slightly lesser differentiation ability between rating categories.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/trad%20metric.png)

### Performance Metrics of Hybrid models

- **Random Forest (Sentiment model) & Logistic Regression (Rating model):** The model performs well when the sentiment weights are kept in the range of 0.0 and 0.6. In this range, the ROC score only slightly improves without impacting other performance metrics. However, the model's performance declines noticeably after the sentiment weight exceeds 0.6, indicating that a high sentiment weight may reduce the model's overall efficacy. With more substantial ROC scores and consistent performance in other areas within this range, it would be a good idea to put the sentiment weight at 0.6 or less to get the best outcomes.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/hybrid%201.png)

- **RNN (Sentiment model) & RNN (Rating model):** It is evident from the data set that the model performs consistently and well when the sentiment weight is between 0.0 and 0.6. The precision metric shows a progressive increase, reaching its highest values at sentiment weights of 0.9 and 1.0, while the validation accuracy within this range peaks at a sentiment weight of 0.3. The recall value is somewhat consistent up to a sentiment weight of 0.2 before beginning to fall moderately, showing that as the sentiment weight increases, it becomes less and less effective at detecting positive cases. Until a sentiment weight of 0.6 indicates balanced classification performance, the F1 score, which thoroughly assesses the model's precision and recall, remains consistent. The ROC score, which shows how well the model can differentiate between classes, gradually rises until a sentiment weight of 0.4, after which it slightly decreases while maintaining a score above 0.9, indicating good model performance. Since greater ROC scores and other stable metrics are seen within this range, maintaining a sentiment weight at or below 0.6 may optimise performance.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/Hybrid%202.png)

- **Random Forest (Sentiment model) & RNN (Rating model):** According to the data, the hybrid model works best when sentiment weights are between 0.0 and 0.6. At these sentiment weight levels, the model maintains constant validation accuracy, precision, and recall metrics, with a modest peak in performance occurring at 0.3 sentiment weight levels. The F1 score remains constant throughout this range, demonstrating a balanced model. A noteworthy improvement in the model's classification performance can be seen in the ROC, which peaks at a sentiment weight of 0.5. Therefore, it is advised to set the sentiment weight at 0.6 or lower to get the best results, as this range shows the greatest ROC values and the most stable results of other metrics.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/hybrid%203.png)

- **RNN (Sentiment model) & Logistic Regression (Rating model):** The performance metrics show that the hybrid model, which combines Logistic Regression (used for ratings) and RNN (used for sentiment analysis), performs reasonably well when the sentiment weight is between 0.0 and 0.4. This performance is characterised by consistent validation accuracy and F1 score, as well as a slight improvement in the ROC score, which peaks at a sentiment weight of 0.3. The ROC score noticeably decreases with a sentiment weight of 0.5 despite other metrics remaining consistent, suggesting a decline in the model's discriminating power. Validation accuracy, recall, and ROC scores gradually decrease as the sentiment weight gets closer to 1.0, suggesting declining performance. Maintaining a sentiment weight below 0.5 for optimal results seems beneficial, as it aligns with higher ROC values and stable performance across other metrics.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/hybrid%204.png)


### Conclusion

This project analyzed 459,367 reviews to gauge customer opinions on certain products or services, observing a generally positive trend in both star ratings and sentiment scores. A notable strong correlation was found between the sentiment scores and star ratings, suggesting consistency in the evaluations. Keyword analysis highlighted the elements influencing customer satisfaction and dissatisfaction. An evaluation of different models showed that traditional models, especially the Logistic Regression model, performed well, while hybrid models excelled at specific sentiment weight thresholds, indicating the importance of sentiment weight in predicting reviews and ratings effectively.

Considering the individual strengths of the models and the nuanced performance improvements in the hybrid configurations, selecting the best model ultimately hinges on the specific requirements of the task at hand. The Logistic Regression model emerges as a formidable choice for star rating predictions, given its high ROC score and balanced performance across other metrics. When a more complex, hybrid approach is sought, especially when integrating sentiment analysis into the fold, the RNN (Sentiment model) & Logistic Regression (Rating model) offer a compelling case for selection, providing a rich, balanced analytical capability that harnesses the strengths of both logistic regression and recurrent neural networks.

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/bar%20chart%20final.png)

![](https://github.com/odogwu25/Hybrid-Recommendation-Systems/blob/main/Images/ALL%20ROC.png)

